<!DOCTYPE html>

<html lang="en">
    <head>

        <!-- set the metadata -->
        <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">

        <!-- set the title -->
        <title>Diagnosis & Prediction Tool</title>

        <!-- link to reset.css -->
        <link rel="stylesheet" href="/static/css/reset.css">

        <!-- link to bootstrap css -->
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/css/bootstrap.min.css"
            rel="stylesheet"
            integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx"
            crossorigin="anonymous">

        <!-- link to style.css -->
        <link rel="stylesheet" href="/static/css/style.css">
    </head>

    <body class="bg-light">

        <!-- header -->
        <div class="container-fullwidth">
            <div class="col-md-12">
                <nav class="navbar navbar-expand-lg navbar-dark bg-dark px-3">
                    <div class="container-fluid">
                        <a class="navbar-brand" href="/">Home</a>
                        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDarkDropdown" aria-controls="navbarNavDarkDropdown" aria-expanded="false" aria-label="Toggle navigation">
                            <span class="navbar-toggler-icon"></span>
                        </button>
                        <div class="collapse navbar-collapse justify-content-end" id="navbarNavDarkDropdown">
                            <ul class="navbar-nav ms-auto">
                                <li class="nav-item dropdown">
                                    <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">
                                        Diagnosis
                                    </a>
                                    <ul class="dropdown-menu dropdown-menu-dark dropdown-menu-end">
                                        <li><a class="dropdown-item" href="/diagnose_diseases_from_symptoms">Disease From Symptoms</a></li>
                                    </ul>
                                </li>
                                <li class="nav-item dropdown">
                                    <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">
                                        Model Development
                                    </a>
                                    <ul class="dropdown-menu dropdown-menu-dark dropdown-menu-end">
                                        <li><a class="dropdown-item" href="/model_disease_predictor">Disease Predictor</a></li>
                                    </ul>
                                </li>
                                <li class="nav-item dropdown">
                                    <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">
                                        About
                                    </a>
                                    <ul class="dropdown-menu dropdown-menu-dark dropdown-menu-end">
                                        <li><a class="dropdown-item" href="/about_developers">The Developers</a></li>
                                        <li><a class="dropdown-item" href="/about_data">The Data</a></li>
                                        <li><a class="dropdown-item" href="/about_accreditations">Accreditations</a></li>
                                    </ul>
                                </li>
                            </ul>
                        </div>
                    </div>
                </nav>
            </div>
        </div>

        <!-- body -->
        <div class="container my-3">
            <div class="row">
                <div class="col-md-12">
                   
                    <!-- title -->
                    <h4>Approach</h4>
                    <p class="fst-normal">
                        To create our diagnosis prediction tool, we took the approach of evaluating 5 different types of classification models 
                        in order to select the one that performed with the most accuracy.  We had some interesting results in that
                        almost all of the models gave us very high accuracy.
                        <br><br>
                        In the end we selected the random forest model because it gave us the most confidence due to our ability to change
                        settings and see fluctuation in the accuracy based on our changes.
                    </p>
                    <h4>Classification Models</h4>
                    <div class="accordion" id="model_development_accordion">
                        <div class="accordion-item">
                            <h2 class="accordion-header" id="heading_knn">
                                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse_knn" aria-expanded="false" aria-controls="collapse_knn">
                                    Logistic Regression Friendly Neighbor (KNN)
                                </button>
                            </h2>
                            <div id="collapse_knn" class="accordion-collapse collapse" aria-labelledby="heading_knn" data-bs-parent="#model_development_accordion">
                                <div class="accordion-body">
                                    <div class="card rounded">
                                        <p class="fst-normal">
                                            KNN is a very easy classification model to implement. It is a "lazy learning algorithm" meaning the whole dataset doesn't need to be trained, 
                                            it just uses the nearest neighbors to obtain results. After looping through a range of odd k values to calculate the score we found that the training and testing scores were 100%. 

                                            We found that KNN doesn't work well with high dimensional data because with a large number of dimensions, the distance between points gets "weird", 
                                            and the distance metrics don't hold up. 

                                            <br><br>
                                            <img title="KNN testing and training scores" class="img-fluid mx-auto rounded" alt="knn1" src="https://github.com/Mreisinger1/diagnosis-prediction-tool/blob/main/Classification%20Models/KNN/knn1.png?raw=true">
                                            <br><br>  
                                            <table>
                                                <tr> 
                                                    <th>K Value</th>
                                                    <th>Training Score</th>
                                                    <th>Testing Score</th>
                                                </tr>
                                                <tr> 
                                                    <td>1</td>
                                                    <td>100%</td>
                                                    <td>100%</td>
                                                </tr>
                                                <tr> 
                                                    <td>3</td>
                                                    <td>100%</td>
                                                    <td>100%</td>
                                                </tr>
                                                <tr> 
                                                    <td>5</td>
                                                    <td>100%</td>
                                                    <td>100%</td>
                                                </tr>
                                                <tr> 
                                                    <td>7</td>
                                                    <td>100%</td>
                                                    <td>100%</td>
                                                </tr>
                                                <tr> 
                                                    <td>9</td>
                                                    <td>100%</td>
                                                    <td>100%</td>
                                                </tr>
                                                <tr> 
                                                    <td>11</td>
                                                    <td>100%</td>
                                                    <td>100%</td>
                                                </tr>
                                            </table>

                                            <br><br>
                                            We also calculated the F1 score to try to identify false positives or negatives to see if the 
                                            100% accuracy result was a result of overtraining.
                                            <br><br>
                                            <img title="KNN testing and training scores" class="img-fluid mx-auto rounded" alt="knn1" src="https://github.com/Mreisinger1/diagnosis-prediction-tool/blob/main/Classification%20Models/KNN/knn2.png?raw=true">   
                                            <br><br>
                                            On a scale from 0-1, 1 is the "perfect" F1 score. We had a range of 0.993-1.0 for all of our F-1 scores. To try and support this result we continued 
                                            on with another model. 
                                        
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="accordion-item">
                            <h2 class="accordion-header" id="heading_nb">
                                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse_nb" aria-expanded="false" aria-controls="collapse_nb">
                                    Naive Bayes
                                </button>
                            </h2>
                            <div id="collapse_nb" class="accordion-collapse collapse" aria-labelledby="heading_nb" data-bs-parent="#model_development_accordion">
                                <div class="accordion-body">
                                    <div class="card rounded">    
                                        <p class="fst-normal">
                                            Naive Bayes is a classification model that is based on applying Naive Bayes theorem with the “naive” 
                                            assumption of conditional independence between every pair of features given the value of the class main variable. 
                                            Bayes theorem states the following relationship:
                                            <br>
                                            <br>
                                            Our accuracy of this model was also 100%. We decided to try another model to test our accuracy.
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="accordion-item">
                            <h2 class="accordion-header" id="heading_dt">
                                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse_dt" aria-expanded="false" aria-controls="collapse_dt">
                                    Decision Tree
                                </button>
                            </h2>
                            <div id="collapse_dt" class="accordion-collapse collapse" aria-labelledby="heading_dt" data-bs-parent="#model_development_accordion">
                                <div class="accordion-body">
                                    <div class="card rounded">   
                                        <p class="fst-normal">
                                            Decision Trees can handle non linear datasets very well and include branches that represent decision-making steps that can lead to a favorable result.
                                            Being that we had such a large dataset we found that small changes in the data can cause a large change in the structure of the decision tree. 
                                            <br><br>
                                            A decision tree is made up of three types of nodes:
                                            <br><br>
                                            Decision Nodes: These type of node have two or more branches
                                            <br><br>
                                            Leaf Nodes: The lowest nodes which represents decision
                                            <br><br>
                                            Root Node: This is also a decision node but at the topmost level
                                            <br><br>
                                            Because our dataset is so large, our decision tree includes mutiple root nodes as shown below: 
                                            <img title="Decisiontree" class="img-fluid mx-auto rounded" alt="decisiontree" src="https://github.com/Mreisinger1/diagnosis-prediction-tool/blob/main/Classification%20Models/Decision Tree/decisiontree.png?raw=true">
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="accordion-item">
                            <h2 class="accordion-header" id="heading_svm">
                                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse_svm" aria-expanded="false" aria-controls="collapse_svm">
                                    Support Vector Machine (SVM)
                                </button>
                            </h2>
                            <div id="collapse_svm" class="accordion-collapse collapse" aria-labelledby="heading_svm" data-bs-parent="#model_development_accordion">
                                <div class="accordion-body">
                                    <div class="card rounded">      
                                        <p class="fst-normal">
                                            Support vector machine (SVM) classifies data by defining a hyperplane decision boundary between classifications.
                                            It finds the best boundary placing the hyperplane at the furthers distance from the closest datapoints for each
                                            class.
                                        </p>
                                        <p>
                                            For multiclass SVM classification, there are two decision function shapes (One-vs-rest and One-vs-One).
                                            In one-vs-rest (default for scikit-learn), each class is distiguished from the rest of the datapoints one
                                            at a time.  In one-vs-one, the data is broken down into multiple binary classifications.
                                        </p>
                                        <p>
                                            Addtionally, there are different kernal functions used to define the decision boundary (hyperplane).  
                                            We used the four most popular kernal functions for our analysis.
                                        </p>
                                        <ol>
                                            <li>1. Linear <br> <img class="img-fluid mx-auto rounded" alt="Linear" src="https://github.com/Mreisinger1/diagnosis-prediction-tool/blob/main/Classification%20Models/SVM/Linear.png?raw=true"> </li>
                                            <li>2. Polynomial <br> <img class="img-fluid mx-auto rounded" alt="Poly" src="https://github.com/Mreisinger1/diagnosis-prediction-tool/blob/main/Classification%20Models/SVM/Polynomial.png?raw=true"></li>
                                            <li>3. Radial Basis Function (RBF) <br> <img class="img-fluid mx-auto rounded" alt="RBF" src="https://github.com/Mreisinger1/diagnosis-prediction-tool/blob/main/Classification%20Models/SVM/RBF.png?raw=true"></li>
                                            <li>4. Sigmoid <br> <img class="img-fluid mx-auto rounded" alt="Sigmoid" src="https://github.com/Mreisinger1/diagnosis-prediction-tool/blob/main/Classification%20Models/SVM/Sigmoid.png?raw=true"></li>
                                        </ol>
                                        <table>
                                            <tr> 
                                                <th>Kernal</th>
                                                <th>Decision Shape</th>
                                                <th>Accuracy</th>
                                            </tr>
                                            <tr> 
                                                <td>Linear</td>
                                                <td>OvO</td>
                                                <td>100%</td>
                                            </tr>
                                            <tr> 
                                                <td>Linear</td>
                                                <td>OvR</td>
                                                <td>100%</td>
                                            </tr>
                                            <tr> 
                                                <td>Polynomial</td>
                                                <td>OvO</td>
                                                <td>96.7%</td>
                                            </tr>
                                            <tr> 
                                                <td>Polynomial</td>
                                                <td>OvR</td>
                                                <td>96.7%</td>
                                            </tr>
                                            <tr> 
                                                <td>RBF</td>
                                                <td>OvO</td>
                                                <td>100%</td>
                                            </tr>
                                            <tr> 
                                                <td>RBF</td>
                                                <td>OvR</td>
                                                <td>100%</td>
                                            </tr>
                                            <tr> 
                                                <td>Sigmoid</td>
                                                <td>OvO</td>
                                                <td>100%</td>
                                            </tr>
                                            <tr> 
                                                <td>Sigmoid</td>
                                                <td>OvR</td>
                                                <td>100%</td>
                                            </tr>
                                        </table>
                                        <br>
                                        <p class="fst-normal">
                                            Being that the results for nearly all of the kernals and decision function combinations was 100%, we were 
                                            concerned with overfitting with this classification model.
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="accordion-item">
                            <h2 class="accordion-header" id="heading_rf">
                                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse_rf" aria-expanded="false" aria-controls="collapse_rf">
                                    Random Forest - Selected Prediction Model
                                </button>
                            </h2>
                            <div id="collapse_rf" class="accordion-collapse collapse" aria-labelledby="heading_rf" data-bs-parent="#model_development_accordion">
                                <div class="accordion-body">
                                    <div class="card rounded">
                                        <p class="fst-normal">
                                            The random forest classification model is a collection of decision trees that are created using a randomly selected subset of the 
                                            features and then averaged together to create the model.  Because it workes with a subset of the features at a time it is faster to
                                            train that the decision tree model.
                                        </p>
                                        <p>
                                            In our random forest classification, the first round of testing after scaling the dataset and training the model resulted in 100% accuracy with both the training and testing data.  
                                            After noting that all of the other models were giving the same results, we modified the values for the max depth (maximum number of levels
                                            we would allow the model to go to) and the number of estimators (branches). This analysis allowed us to evaluate if our model was being overfit; 
                                            if our data was not lending itself to classification; or give us confidence that our model was really 100% accurate.
                                        </p>
                                        <table>
                                            <tr> 
                                                <th>Max Depth</th>
                                                <th>Estimators</th>
                                                <th>Training Accuracy</th>
                                                <th>Testing Accuracy</th>
                                            </tr>
                                            <tr> 
                                                <td>5</td>
                                                <td>500</td>
                                                <td>100%</td>
                                                <td>100%</td>
                                            </tr>
                                            <tr> 
                                                <td>5</td>
                                                <td>400</td>
                                                <td>100%</td>
                                                <td>100%</td>
                                            </tr>
                                            <tr> 
                                                <td>5</th>
                                                <td>300</td>
                                                <td>100%</td>
                                                <td>100%</td>
                                            </tr>
                                            <tr> 
                                                <td>5</th>
                                                <td>200</td>
                                                <td>99.73%</td>
                                                <td>99.84%</td>
                                            </tr>
                                            <tr> 
                                                <td>4</td>
                                                <td>300</td>
                                                <td>99.76%</td>
                                                <td>99.76%</td>
                                            </tr>
                                            <tr> 
                                                <td>3</td>
                                                <td>100</td>
                                                <td>95.99%</td>
                                                <td>96.42%</td>
                                            </tr>
                                            <tr> 
                                                <td>2</td>
                                                <td>200</td>
                                                <td>96.18%</td>
                                                <td>96.34%</td>
                                            </tr>
                                        </table>
                                        <br>
                                        <p class="fst-normal">
                                            As shown in the table, we were able to see that with a lower number of levels to our tree and branches in the forest; we saw
                                            a lower accuracy rate.  Additionally, the testing and training accuracy remained close in all cases.  We interpret this as proving
                                            that our data was highly suited to training a classification model for the 41 specific diseases and 131 symptoms it contained.
                                        </p>
                                        <p>
                                            This gave us the confidence in our data and the Random Forest Classification model to move foward and select the Random Forest Classsifier (Max Depth = 5, Estimators = 300) for our predictions.
                                        </p>
                                        <br>
                                        <h5>Branch of Our Random Forest Classification Model</h5>
                                        <img title="Branch of Random Forest" class="img-fluid mx-auto rounded" alt="randomForest_branch" src="https://github.com/Mreisinger1/diagnosis-prediction-tool/blob/main/Classification%20Models/RF/RandomForest_Visualization2.png?raw=true">
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- import bootstrap js library -->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/js/bootstrap.bundle.min.js"
                integrity="sha384-A3rJD856KowSb7dwlZdYEkO39Gagi7vIsF0jrRAoQmDKKtQBHUuLZ9AsSv4jD4Xa"
                crossorigin="anonymous"></script>
    </body>
</html>